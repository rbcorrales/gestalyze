# Gestalyze

![Gestalyze Logo](gestalyze-logo-text.svg)

**Gesture-based Smart Home Interface using Sign Language and Hand Pose Recognition**

ğŸ”§ Built with [FastAPI](https://fastapi.tiangolo.com), [MediaPipe](https://ai.google.dev/edge/mediapipe/solutions/vision/hand_landmarker), [React](https://react.dev), [MQTT](https://mqtt.org) and [Home Assistant](https://www.home-assistant.io).

ğŸ” Empowering accessibility through open-source gesture control.

---

## ğŸ“¦ Overview

Gestalyze is an open-source project that enables real-time hand gesture recognition for controlling smart home devices. By combining computer vision and machine learning techniques, the system interprets static hand poses â€” including alphabet signs from sign language â€” and sends commands to home automation platforms like [Home Assistant](https://www.home-assistant.io).

The system is modular, lightweight, and designed for low-power environments using technologies such as [MQTT](https://mqtt.org), [MediaPipe Hands](https://ai.google.dev/edge/mediapipe/solutions/vision/hand_landmarker), and [React](https://react.dev). Users can extend, train custom models, and integrate new gesture mappings for full control over their smart environment.

---

## ğŸ¯ Key Features

- âœ‹ Real-time hand detection and finger tracking with [MediaPipe](https://ai.google.dev/edge/mediapipe/solutions/vision/hand_landmarker).
- ğŸ”  ASL static alphabet recognition using trainable ML classifiers.
- ğŸ’¡ Smart home integration via [MQTT](https://mqtt.org) and [Home Assistant](https://www.home-assistant.io) plugins.
- âš¡ Low-latency WebSocket communication between frontend and backend.
- ğŸ“· Frontend web app built in [React](https://react.dev) + WebRTC.
- ğŸŒ Multilingual interface with i18n support.
- ğŸ§  Supports custom and pre-trained gesture models.
- ğŸ“Š Visualization tools for metrics, training and evaluation.
- ğŸ§ª Designed for reproducible research and experimentation.

---

## ğŸ§± System Architecture

This repository is currently structured as a monorepo to simplify development, deployment, and cross-component coordination. As the project matures, it is expected that individual components â€” such as the frontend, backend, and Home Assistant integrations â€” may be separated into distinct repositories to improve modularity and scalability.

---

## ğŸ—ƒï¸ Project Structure

```
gestalyze/
â”œâ”€â”€ backend/               # Gestalyze backend server
â”‚   â”œâ”€â”€ inference/         # ML model inference and processing
â”‚   â”œâ”€â”€ mqtt/              # MQTT client and message handling
â”‚   â””â”€â”€ ssl/               # SSL certificates and configuration
â”œâ”€â”€ config/                # Project-wide configuration files (e.g., MQTT)
â”œâ”€â”€ datasets/              # Public and custom gesture datasets
â”œâ”€â”€ docs/                  # Assets and documentation support files
â”œâ”€â”€ frontend/              # React web app for video capture and UI
â”œâ”€â”€ homeassistant/         # Plugins and custom components for Home Assistant
â”‚   â”œâ”€â”€ custom_components/ # Custom Home Assistant integration
â”‚   â””â”€â”€ gestalyze_plugin/  # Home Assistant plugin for gestalyze
â”œâ”€â”€ models/                # Serialized ML models (.joblib)
â”œâ”€â”€ training/              # Training scripts and model experiments
â”œâ”€â”€ website/               # Public website ([https://gestalyze.com](gestalyze.com))
â””â”€â”€ Makefile               # Project task automation
```

---

## ğŸš€ Getting Started

> Requires Python 3.10+, Node.js 18+, and Mosquitto MQTT

```bash
# Clone repository
git clone https://github.com/yourname/gestalyze.git
cd gestalyze

# Install Python & Node dependencies
make install

# Start development servers
make dev
```

Open your browser to `http://localhost:5173` to launch the interface.

---

## ğŸ§  Training Custom Models

To train your own gesture recognition model:

```bash
# Example with custom dataset
make extract-landmarks DATASET_NAME=your_dataset
make train MODEL_TYPE=custom DATASET_NAME=your_dataset
```

Models are saved to `models/` and can be switched via the interface.

---

## ğŸ› ï¸ Makefile Commands

Common tasks for development and training:

- `make install` â€” Installs Python and Node.js dependencies
- `make dev` â€” Starts both frontend and backend in development mode
- `make build` â€” Builds the frontend for production
- `make run` â€” Runs the backend with built frontend and MQTT
- `make run-ssl` â€” Runs backend with SSL enabled
- `make train MODEL_TYPE=custom DATASET_NAME=name` â€” Trains a gesture model
- `make extract-landmarks DATASET_NAME=name` â€” Extracts MediaPipe landmarks from dataset
- `make clean` â€” Cleans compiled files, build folders and caches
- `make mqtt-start`, `make mqtt-stop` â€” Start/stop the Mosquitto broker
- `make ssl-key-gen` â€” Generates self-signed SSL certificates
- `make deploy-ha` â€” Deploys custom integration to Home Assistant
- `make website-dev` â€” Starts the public website in development mode
- `make website-build` â€” Builds the public website for production
- `make version` â€” Displays version info
- `make help` â€” Shows available commands

For advanced options and custom variables, inspect the `Makefile`.

---

## ğŸ’¡ Smart Home Integration

Gestalyze communicates with [Home Assistant](https://www.home-assistant.io/) via [MQTT](https://mqtt.org). You can:

- Use our **plugin** (external service)
- Or the **custom integration** under `homeassistant/custom_components/gestalyze/`

This enables the use of sensors and event-based automations based on detected hand gestures.

---

## ğŸ”’ Privacy & Security

All gesture processing happens **locally** on your device.
No images or biometric data are transmitted or stored externally.
See [`Privacy Policy`](https://gestalyze.com/privacy) for full details.

---

## ğŸ“– Documentation

- Full system documentation: https://gestalyze.com
- Datasets, models and training configuration
- Code walkthroughs, diagrams and tutorials

---

## ğŸ“œ License

This project is licensed under the Apache License 2.0 â€” see [LICENSE](./LICENSE) for details.

---

## ğŸ¤ Contributing

Pull requests, feature ideas and issue reports are welcome.
For contributions, see [CONTRIBUTING.md](./CONTRIBUTING.md).

---

## ğŸ‘‹ Acknowledgments

- [MediaPipe](https://ai.google.dev/edge/mediapipe/solutions/vision/hand_landmarker) by Google for hand tracking
- [Home Assistant](https://www.home-assistant.io) for smart home integration
- Hugging Face and Kaggle for gesture datasets
- All open-source contributors who inspire and make projects like this possible

---

## ğŸ§­ Roadmap & TODO

Gestalyze is still under active development. Some upcoming features and improvements include:

- [ ] Support for multiple simultaneous frontend clients.
- [ ] Real-time model hot-swapping via the interface.
- [ ] Integration with additional smart home platforms.
- [ ] Gesture recording and labeling tools for data collection.
- [ ] Extended dynamic gesture recognition (sequential actions).
- [ ] Accessibility testing with real users and community feedback.
- [ ] CI/CD automation for releases and plugin deployment.
- [ ] Docker-based deployment flow.
- [ ] Unit testing for every module.
- [ ] Improved model modularity for easier experimentation and integration.
- [ ] Continued refinement of gesture recognition model accuracy.

---

Â© 2025 â€” Initially developed by [rbcorrales](https://github.com/rbcorrales).
